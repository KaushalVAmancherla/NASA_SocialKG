{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab484c4c-fefd-4f2a-90e8-81b18fc58129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
    "\n",
    "from helper_funcs import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75a5e1f-ffb0-4059-b250-9ea1f7812dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d532f97d-eb25-44ec-ba06-95258dda7c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nd986d8740c844731aff12092eed64236 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.parse(ontology_fp, format=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f78d58-9a65-4df4-a13c-cb1d2f08be75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ontology IRI: http://www.semanticweb.org/kaushalamancherla/ontologies/2025/4/social_KG\n"
     ]
    }
   ],
   "source": [
    "ont_iri = g.value(None, RDF.type, OWL.Ontology)\n",
    "print(\"\\nOntology IRI:\", ont_iri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31bb8ac3-5523-439f-90b5-5fc3c93d93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONTO = Namespace(ont_iri + \"#\")\n",
    "g.bind(\"onto\", ONTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea489f2-7953-49a1-b4fc-c46f52313e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Namespace(ont_iri + \"/data/\")\n",
    "g.bind(\"data\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2956b22-12cb-4ab6-a4ab-794548974b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XSD base URI: http://www.w3.org/2001/XMLSchema#\n",
      "OWL base URI: http://www.w3.org/2002/07/owl#\n",
      "RDF base URI: http://www.w3.org/1999/02/22-rdf-syntax-ns#\n",
      "DATA base URI: http://www.semanticweb.org/kaushalamancherla/ontologies/2025/4/social_KG/data/\n",
      "ONTO base URI: http://www.semanticweb.org/kaushalamancherla/ontologies/2025/4/social_KG#\n"
     ]
    }
   ],
   "source": [
    "print(\"XSD base URI:\", str(XSD))\n",
    "print(\"OWL base URI:\", str(OWL))\n",
    "print(\"RDF base URI:\", str(RDF))\n",
    "print(\"DATA base URI:\", str(DATA))\n",
    "print(\"ONTO base URI:\", str(ONTO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97035310-0c60-4d6e-b061-a7e172cebd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.bind(\"rdf\",  RDF)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"owl\",  OWL)\n",
    "g.bind(\"xsd\",  XSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693307f3-a893-4380-9e71-f803f574ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_openalex_author_data = read_json_from_local(person_raw_openalex_data_fp)\n",
    "raw_openalex_inst_data = read_json_from_local(inst_raw_openalex_data_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f004ecb-3172-42bc-9ae1-f3b1cc777e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### HELPER FUNCTIONS #######\n",
    "def mint_uri(*segments: str):\n",
    "    \"\"\"\n",
    "    entity_type: e.g. \"person\" or \"organization\"\n",
    "    local_id: the unique ID (e.g. OpenAlex ID without the URL prefix)\n",
    "    \"\"\"\n",
    "    path = \"/\".join(segments)\n",
    "    return URIRef(DATA + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9ae4cde-3c68-4ffb-8de9-4ff71842f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_citation_and_work_properties(node_uri,node_id,counts_metadata,node_type):\n",
    "    for rec in counts_metadata:\n",
    "        yr = rec[\"year\"]\n",
    "    \n",
    "        # Mint a URI for this year's citation metadata\n",
    "        cnode = mint_uri(f\"{node_type}/{node_id}/citationCountMetadata\", str(yr))\n",
    "    \n",
    "        g.add((cnode, RDF.type, ONTO.CitationCountMetadata))\n",
    "        g.add((cnode, ONTO.year,     Literal(yr, datatype=XSD.gYear)))\n",
    "        g.add((cnode, ONTO.quantity, Literal(rec[\"cited_by_count\"], datatype=XSD.integer)))\n",
    "        g.add((node_uri, ONTO.hasCitationData, cnode))\n",
    "    \n",
    "        # Mint a URI for this year's works metadata\n",
    "        wnode = mint_uri(f\"{node_type}/{node_id}/worksCountMetadata\", str(yr))\n",
    "\n",
    "        g.add((wnode, RDF.type, ONTO.WorksCountMetadata))\n",
    "        g.add((wnode, ONTO.year,     Literal(yr, datatype=XSD.gYear)))\n",
    "        g.add((wnode, ONTO.quantity, Literal(rec[\"works_count\"], datatype=XSD.integer)))\n",
    "        g.add((node_uri, ONTO.hasWorksData, wnode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516ab4ca-157f-4f4a-9e4b-d6cdcb30d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### GLOBAL CACHE FOR INSTITUTION DATA ######\n",
    "global_inst_cache = {} #id -> URI for institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bd9a750-0969-483c-b78f-47c80e61a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_institution(i_id,inst_uri,metadata):\n",
    "    # 1) mint and type the org node\n",
    "    full_id  = metadata[\"id\"]\n",
    "\n",
    "    # 2) core metadata\n",
    "    g.add((inst_uri, ONTO.openalex_id, Literal(full_id, datatype=XSD.string)))\n",
    "    \n",
    "    display_name = metadata[\"display_name\"]\n",
    "    g.add((inst_uri, ONTO.name, Literal(display_name)))\n",
    "    \n",
    "    # 3) flat data properties\n",
    "    c = metadata.get(\"cited_by_count\")\n",
    "    g.add((inst_uri, ONTO.citedByCount, Literal(c, datatype=XSD.int)))\n",
    "    \n",
    "    if \"grants_count\" in metadata:\n",
    "        grants = metadata[\"grants_count\"]\n",
    "        \n",
    "        g.add((inst_uri, ONTO.grantsCount, Literal(grants, datatype=XSD.int)))\n",
    "\n",
    "    # 4) summary_stats\n",
    "    stats = metadata.get(\"summary_stats\", {})\n",
    "    \n",
    "    if mean2 := stats.get(\"2yr_mean_citedness\"):\n",
    "        g.add((inst_uri, ONTO.twoYearMeanCitedness,Literal(mean2, datatype=XSD.double)))\n",
    "        \n",
    "    if h := stats.get(\"h_index\"):\n",
    "        g.add((inst_uri, ONTO.hIndex, Literal(h, datatype=XSD.int)))\n",
    "        \n",
    "    if i10 := stats.get(\"i10_index\"):\n",
    "        g.add((inst_uri, ONTO.i10Index, Literal(i10, datatype=XSD.int)))\n",
    "\n",
    "    # 5) role-based works counts\n",
    "    for role in metadata.get(\"roles\", []):\n",
    "        r = role.get(\"role\")\n",
    "        wc = role.get(\"works_count\")\n",
    "            \n",
    "        if r == \"publisher\":\n",
    "            g.add((inst_uri, ONTO.publisher_works_count,Literal(wc, datatype=XSD.int)))\n",
    "        elif r == \"funder\":\n",
    "            g.add((inst_uri, ONTO.funder_works_count,Literal(wc, datatype=XSD.int)))\n",
    "        elif r == \"institution\":\n",
    "            g.add((inst_uri, ONTO.institution_works_count,Literal(wc, datatype=XSD.int)))\n",
    "\n",
    "    counts = metadata['counts_by_year']\n",
    "    add_citation_and_work_properties(inst_uri,i_id,counts,\"organization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc02a3ea-2a93-4224-b2f2-1a4b1e143a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_affiliations(person_uri,affiliations,isForLast):\n",
    "    for affiliation in affiliations: \n",
    "        if not isForLast:\n",
    "            full_id = affiliation['institution']['id']\n",
    "            years = affiliation.get(\"years\", [])\n",
    "        else:\n",
    "            full_id = affiliation['id']\n",
    "            \n",
    "        parsed_id = full_id.rsplit(\"/\", 1)[-1]\n",
    "        person_local = str(person_uri).rsplit(\"/\", 1)[-1]\n",
    "        \n",
    "        #1. ADD NODE TO GRAPH IF NOT ALREADY THERE\n",
    "        if parsed_id not in global_inst_cache:\n",
    "            inst_type = raw_openalex_inst_data[parsed_id]['inst_type']\n",
    "            inst_uri = mint_uri(\"organization\" if inst_type == ORG else \"group\",parsed_id)\n",
    "\n",
    "            #add node into graph\n",
    "            g.add((\n",
    "                inst_uri,\n",
    "                RDF.type,\n",
    "                ONTO.Organization if inst_type == ORG else ONTO.Group\n",
    "            ))\n",
    "\n",
    "            #add the institution metadata to this node (data property, we only need to do this one time upon init)\n",
    "            process_institution(parsed_id,inst_uri,raw_openalex_inst_data[parsed_id]['metadata'])\n",
    "\n",
    "            #add to global cache\n",
    "            global_inst_cache[parsed_id] = inst_uri\n",
    "            \n",
    "        inst_uri = global_inst_cache[parsed_id]\n",
    "        \n",
    "        #2. create the edges with the Affiliation class capturing the temporal dependencies\n",
    "        if isForLast: #simply add (Person) -lastKnownInstitution-> global_inst_cache[parsed_id]\n",
    "            g.add((person_uri, ONTO.lastKnownInstitution, inst_uri))\n",
    "            continue\n",
    "\n",
    "        #otherwise, we default to this case:\n",
    "        #3. (Person) -worksFor-> Organization\n",
    "        years = sorted(set(years))\n",
    "        segments = []\n",
    "        \n",
    "        if years:\n",
    "            seg_start = seg_prev = years[0]\n",
    "            for y in years[1:]:\n",
    "                if y == seg_prev + 1:\n",
    "                    # still contiguous\n",
    "                    seg_prev = y\n",
    "                else:\n",
    "                    # end of a run\n",
    "                    segments.append((seg_start, seg_prev))\n",
    "                    seg_start = seg_prev = y\n",
    "                    \n",
    "            segments.append((seg_start, seg_prev))\n",
    "    \n",
    "        # 3b.iii) for each segment, mint a distinct Affiliation node\n",
    "        for start_year, end_year in segments:\n",
    "            # URI-safe suffix, e.g. \"2017-2019\" or \"2015\"\n",
    "            period = f\"{start_year}-{end_year}\" if start_year != end_year else f\"{start_year}\"\n",
    "            aff_uri = mint_uri(\"affiliation\", person_local, parsed_id, period)\n",
    "        \n",
    "            # a) type\n",
    "            if (aff_uri, RDF.type, ONTO.Affiliation) not in g:\n",
    "                g.add((aff_uri, RDF.type, ONTO.Affiliation))\n",
    "        \n",
    "            # b) timestamp props\n",
    "            g.add((aff_uri, ONTO.affiliationStartYear,\n",
    "                   Literal(start_year, datatype=XSD.gYear)))\n",
    "            g.add((aff_uri, ONTO.affiliationEndYear,\n",
    "                   Literal(end_year,   datatype=XSD.gYear)))\n",
    "        \n",
    "            g.add((person_uri, ONTO.hasAffiliation, aff_uri))\n",
    "            \n",
    "            if (aff_uri, ONTO.affiliatedOrganization, inst_uri) not in g:\n",
    "                g.add((aff_uri, ONTO.affiliatedOrganization, inst_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f50b9c68-e37d-4cd2-ad69-e45675074b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_author_metadata(author,metadata_dict):\n",
    "    ####### 1. CREATE PERSON NODE AND ADD THE SIMPLE PERSON DATA PROPERTIES ######\n",
    "    local_id  = metadata_dict['id'].rsplit(\"/\", 1)[-1]\n",
    "    \n",
    "    person_uri = mint_uri(\"person\", local_id)\n",
    "    #print(person_uri)\n",
    " \n",
    "    g.add((person_uri, RDF.type, ONTO.Person)) #init node of type Person\n",
    "\n",
    "    #attach data properties: openalexId, name, worksCount, citedByCount\n",
    "    display_name = metadata_dict['display_name']\n",
    "    works_count = metadata_dict['works_count']\n",
    "    cited_by_count = metadata_dict['cited_by_count']\n",
    "    \n",
    "    g.add((person_uri, ONTO.openalex_id, Literal(local_id, datatype=XSD.string)))\n",
    "    g.add((person_uri, ONTO.name, Literal(display_name)))\n",
    "    g.add((person_uri, ONTO.worksCount, Literal(works_count, datatype=XSD.integer)))\n",
    "    g.add((person_uri, ONTO.citedByCount, Literal(cited_by_count, datatype=XSD.integer)))\n",
    "\n",
    "    summary_stats = metadata_dict[\"summary_stats\"]\n",
    "\n",
    "    # 1. Two‐year mean citedness → xsd:double\n",
    "    if \"2yr_mean_citedness\" in summary_stats:\n",
    "        g.add((person_uri,ONTO[\"2yr_mean_citedness\"],Literal(summary_stats[\"2yr_mean_citedness\"], datatype=XSD.double)))\n",
    "    \n",
    "    # 2. h‐index → xsd:integer\n",
    "    if \"h_index\" in summary_stats:\n",
    "        g.add((person_uri,ONTO.h_index,Literal(summary_stats[\"h_index\"], datatype=XSD.integer)))\n",
    "    \n",
    "    # 3. i10‐index → xsd:integer\n",
    "    if \"i10_index\" in summary_stats:\n",
    "        g.add((person_uri,ONTO.i10_index,Literal(summary_stats[\"i10_index\"], datatype=XSD.integer)))\n",
    "\n",
    "    #### ADDING YEARLY WORKS AND YEARLY CITATIONS ####\n",
    "    counts = metadata_dict['counts_by_year']\n",
    "    add_citation_and_work_properties(person_uri,local_id,counts,\"person\")\n",
    "\n",
    "    ##### PARSING INSTITUTION AFFILIATIONS ######\n",
    "    '''\n",
    "    This will require first instantiating an institution as either an organization or a group, then\n",
    "    we attach the associated metadata with it. However, it is important to check if the node for the institution already exists\n",
    "    Basically, what we do is if a node is new, attach it into the graph, and then append the necessary metadata to it.\n",
    "\n",
    "    Lastly, we must get a list of all institutions that are currently in the graph (this is simply the organizations class as group is a subclass\n",
    "    of organizations). When we have these nodes, for a given institution we are currently processing, intersect the list of those graph nodes and\n",
    "    the list of organizations with the target relation (i.e. child, parent, etc.) and establish the necessary edge (subGroupOf, etc.)\n",
    "    Now, we must note not to duplicately add edges (i.e. if such an edge already exists, leave it).\n",
    "    \n",
    "    Once those nodes are populated, we add the edges of - (Person) -worksFor-> Organization  and - (Person) -lastKnownInstitution-> Organization with the\n",
    "    associated time stamps via the Affiliation class\n",
    "    '''\n",
    "    affiliations = metadata_dict['affiliations']\n",
    "    last_known = metadata_dict['last_known_institutions']\n",
    "    \n",
    "    process_affiliations(person_uri,affiliations,False)\n",
    "    process_affiliations(person_uri,last_known,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a19866-75ea-4251-b25b-3034116190a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOAD THE WORKS DATA #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb1e579-5d50-4b0b-936f-484169cbe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_works_metadata():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f1ece-0681-4c0b-9230-a994f6cd4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for author,metadata_dict in raw_openalex_author_data.items():\n",
    "    parse_author_metadata(author,metadata_dict)\n",
    "    parse_works_metadata("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
